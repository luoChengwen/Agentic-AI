{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luoChengwen/Agentic-AI/blob/main/LLM_Function_Calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwe2eeOQB0cC",
        "outputId": "22d3b977-d75a-4003-e8f9-64560b03872b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? what is the file 'README.md' about\n",
            "Tool Name: list_files\n",
            "Tool Arguments: {}\n",
            "Result: ['.config', 'README.md', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "from litellm import completion\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "\n",
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    \"read_file\": read_file\n",
        "}\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of files in the directory.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Our rules are simplified since we don't have to worry about getting a specific output format\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\"\"\"\n",
        "}]\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "messages = agent_rules + memory\n",
        "\n",
        "response = completion(\n",
        "    model=\"openai/gpt-4o\",\n",
        "    messages=messages,\n",
        "    tools=tools,\n",
        "    max_tokens=1024\n",
        ")\n",
        "\n",
        "# Extract the tool call from the response, note we don't have to parse now!\n",
        "tool = response.choices[0].message.tool_calls[0]\n",
        "tool_name = tool.function.name\n",
        "tool_args = json.loads(tool.function.arguments)\n",
        "result = tool_functions[tool_name](**tool_args)\n",
        "\n",
        "print(f\"Tool Name: {tool_name}\")\n",
        "print(f\"Tool Arguments: {tool_args}\")\n",
        "print(f\"Result: {result}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0]"
      ],
      "metadata": {
        "id": "iu05kfbLw4zp",
        "outputId": "dd73ed36-7553-47ca-99da-b446f28b6303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='list_files'), id='call_7lz1mTnwlJk4psR3gDC5pWuL', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool"
      ],
      "metadata": {
        "id": "s7gd-i5hxc7c",
        "outputId": "947e9786-3974-45b2-e3c7-50e266457852",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletionMessageToolCall(function=Function(arguments='{}', name='list_files'), id='call_7lz1mTnwlJk4psR3gDC5pWuL', type='function')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "messages = agent_rules + memory\n",
        "\n",
        "\n",
        "\n",
        "MAX_STEPS = 5\n",
        "for step in range(MAX_STEPS):\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "\n",
        "    message = response.choices[0].message\n",
        "    print(message)\n",
        "    # Extract the tool call from the response, note we don't have to parse now!\n",
        "    tool = response.choices[0].message.tool_calls[0]\n",
        "    tool_name = tool.function.name\n",
        "    tool_args = json.loads(tool.function.arguments)\n",
        "    result = tool_functions[tool_name](**tool_args)\n",
        "\n",
        "    print(f\"Tool Name: {tool_name}\")\n",
        "    print(f\"Tool Arguments: {tool_args}\")\n",
        "    print(f\"Result: {result}\")\n",
        "    messages.append({\"role\": \"assistant\", \"tool_calls\": [tool]})\n",
        "    print('hello')\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"tool\",\n",
        "        \"tool_call_id\": tool.id,\n",
        "        \"content\": str(result)\n",
        "    })\n"
      ],
      "metadata": {
        "id": "qcuPamhQxhnV",
        "outputId": "ec85e67d-0df7-404e-e694-bab3212f13e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? what is the file 'README.md' about\n",
            "Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='list_files'), id='call_SzOWqFXjDrdWdTB11hs6pVZD', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[])\n",
            "Tool Name: list_files\n",
            "Tool Arguments: {}\n",
            "Result: ['.config', 'README.md', 'sample_data']\n",
            "hello\n",
            "Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"file_name\":\"README.md\"}', name='read_file'), id='call_ioEXbnScZLXtdwZ5pGQf1oUh', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[])\n",
            "Tool Name: read_file\n",
            "Tool Arguments: {'file_name': 'README.md'}\n",
            "Result: This directory includes a few sample datasets to get you started.\n",
            "\n",
            "*   `california_housing_data*.csv` is California housing data from the 1990 US\n",
            "    Census; more information is available at:\n",
            "    https://docs.google.com/document/d/e/2PACX-1vRhYtsvc5eOR2FWNCwaBiKL6suIOrxJig8LcSBbmCbyYsayia_DvPOOBlXZ4CAlQ5nlDD8kTaIDRwrN/pub\n",
            "\n",
            "*   `mnist_*.csv` is a small sample of the\n",
            "    [MNIST database](https://en.wikipedia.org/wiki/MNIST_database), which is\n",
            "    described at: http://yann.lecun.com/exdb/mnist/\n",
            "\n",
            "*   `anscombe.json` contains a copy of\n",
            "    [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet); it\n",
            "    was originally described in\n",
            "\n",
            "    Anscombe, F. J. (1973). 'Graphs in Statistical Analysis'. American\n",
            "    Statistician. 27 (1): 17-21. JSTOR 2682899.\n",
            "\n",
            "    and our copy was prepared by the\n",
            "    [vega_datasets library](https://github.com/altair-viz/vega_datasets/blob/4f67bdaad10f45e3549984e17e1b3088c731503d/vega_datasets/_data/anscombe.json).\n",
            "\n",
            "hello\n",
            "Message(content='The `README.md` file provides an overview of sample datasets available in the directory:\\n\\n1. **California Housing Data:**\\n   - Files: `california_housing_data*.csv`\\n   - Source: 1990 US Census\\n   - More Info: [Link](https://docs.google.com/document/d/e/2PACX-1vRhYtsvc5eOR2FWNCwaBiKL6suIOrxJig8LcSBbmCbyYsayia_DvPOOBlXZ4CAlQ5nlDD8kTaIDRwrN/pub)\\n\\n2. **MNIST Database Samples:**\\n   - Files: `mnist_*.csv`\\n   - Description: Small sample of the [MNIST database](https://en.wikipedia.org/wiki/MNIST_database)\\n   - More Info: [Link](http://yann.lecun.com/exdb/mnist/)\\n\\n3. **Anscombe\\'s Quartet:**\\n   - File: `anscombe.json`\\n   - Original Source: Anscombe, F. J. (1973). \"Graphs in Statistical Analysis\". American Statistician. 27 (1): 17-21.\\n   - Prepared by: [Vega Datasets Library](https://github.com/altair-viz/vega_datasets/blob/4f67bdaad10f45e3549984e17e1b3088c731503d/vega_datasets/_data/anscombe.json)', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'NoneType' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-443410401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Extract the tool call from the response, note we don't have to parse now!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtool_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtool_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M2yVXFff2MrV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}